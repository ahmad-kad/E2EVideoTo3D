FROM apache/airflow:2.6.3-python3.7

USER root

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgl1-mesa-glx \
    wget \
    git \
    curl \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Switch to airflow user to install Python dependencies
USER airflow

# Set Python environment
ENV PYTHONWARNINGS="ignore::DeprecationWarning"

# Install our custom requirements in smaller, more manageable groups
COPY --chown=airflow:root requirements-airflow-fixed.txt /opt/airflow/requirements-airflow.txt

# Install core packages first
RUN pip install --no-cache-dir --upgrade pip setuptools wheel && \
    pip install --no-cache-dir numpy>=1.19.0,<1.21.0 pillow>=8.0.0,<9.0.0

# Install remaining packages in groups to isolate potential issues
RUN pip install --no-cache-dir docker>=5.0.0,<6.0.0 kubernetes>=21.7.0,<24.0.0
RUN pip install --no-cache-dir boto3>=1.20.0,<1.26.0 minio>=7.0.0,<7.1.0
RUN pip install --no-cache-dir opencv-python-headless>=4.5.0,<4.6.0
RUN pip install --no-cache-dir jupyter>=1.0.0,<2.0.0
RUN pip install --no-cache-dir trimesh>=3.9.0,<3.15.0 numpy-stl>=2.16.0,<3.0.0 pyntcloud>=0.1.0,<0.2.0

# Try to install open3d but allow failure
RUN pip install --no-cache-dir open3d>=0.13.0,<0.16.0 || echo "open3d installation failed, continuing anyway"

# Install Airflow providers
RUN pip install --no-cache-dir apache-airflow-providers-docker>=3.7.0,<4.0.0 \
    apache-airflow-providers-slack>=4.0.0,<5.0.0 \
    apache-airflow-providers-amazon>=7.3.0,<8.0.0 \
    apache-airflow-providers-google>=10.0.0,<11.0.0 \
    apache-airflow-providers-cncf-kubernetes>=5.1.0,<6.0.0

# Try to install the rest with less strict dependencies
RUN pip install --no-cache-dir great-expectations>=0.13.0 evidently>=0.1.0 dbt-core>=1.0.0 || echo "Some packages couldn't be installed, continuing anyway"

# Create directories
USER root
RUN mkdir -p /opt/airflow/data/input \
    /opt/airflow/data/output \
    /opt/airflow/data/videos \
    && chown -R airflow:root /opt/airflow/data

# Copy scripts
COPY --chown=airflow:root docker/scripts/airflow-entrypoint.sh /opt/airflow/
RUN chmod +x /opt/airflow/airflow-entrypoint.sh

USER airflow

# Set Python path
ENV PYTHONPATH=/opt/airflow:$PYTHONPATH

ENTRYPOINT ["/opt/airflow/airflow-entrypoint.sh"] 